{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dcd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319cd5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from basicsr.archs.edvr_arch import EDVR\n",
    "from basicsr.archs.edvrOriginal_arch import EDVRoriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e1b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5880ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "toPIL = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153e81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_540='video_540.mp4'\n",
    "video_360='video_360.mp4'\n",
    "video_216='video_216.mp4'\n",
    "video_4k='video_4k.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d8cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list=[video_540,video_360,video_216]\n",
    "resolution=['540p','360p','216p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b212f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDVR_x4=EDVRoriginal(num_feat=128,num_reconstruct_block=40)\n",
    "EDVR_x6=EDVR(num_feat=128,num_reconstruct_block=40,upscale=6,scale_1=2,scale_2=3)\n",
    "EDVR_x10=EDVR(num_feat=64,num_reconstruct_block=40,upscale=10,scale_1=2,scale_2=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f15cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_x4=torch.load('./models/EDVR_L_x4_SR_REDS_official-9f5f5039.pth')\n",
    "state_x6=torch.load('./models/EDVR_x6.pth')\n",
    "state_x10=torch.load('./models/EDVR_x10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2eba8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDVR_x4.load_state_dict(state_x4['params'], strict=False)\n",
    "EDVR_x6.load_state_dict(state_x6['params'], strict=False)\n",
    "EDVR_x10.load_state_dict(state_x10['params'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8819a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=[EDVR_x4,EDVR_x6,EDVR_x10]\n",
    "model_list=[EDVR_x4,EDVR_x6,EDVR_x4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358d6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR_upscale(model,in_img,num_frame=5):\n",
    "    in_img=in_img[:,:,::-1]\n",
    "    img_tensor=torch.unsqueeze(to_tensor(in_img.copy()),0)\n",
    "    img_tensors=torch.stack([img_tensor]*num_frame,1)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        torch.cuda.empty_cache()\n",
    "        model=model.to(device)\n",
    "        img_tensors=img_tensors.to(device)\n",
    "        pred=model(img_tensors)\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.array(toPIL(pred.data[0]).convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35a4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(video,sr_freq,resolution,model,write_video=False,output=None,ref_video=None):\n",
    "    count=0\n",
    "    cap=cv2.VideoCapture(video)\n",
    "    video_writer=None\n",
    "    if write_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "        video_writer=cv2.VideoWriter(output,fourcc,60,(3840,2160),True)\n",
    "    start=time.time()\n",
    "    t2=0\n",
    "    while True:\n",
    "        s=time.time()\n",
    "        ret,frame=cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count%sr_freq==0:\n",
    "            frame=SR_upscale(model,frame)\n",
    "            # if the result is not good enough on x6 and x10, it can try first scale 4 times, then use BIcubic to upscale to 4K video\n",
    "            #if resolution !='540p':\n",
    "            #    frame=cv2.resize(frame,(3840,2160),interpolation=cv2.INTER_CUBIC)\n",
    "        else#:\n",
    "            frame=cv2.resize(frame,(3840,2160),interpolation=cv2.INTER_CUBIC)\n",
    "        frame=np.uint8(frame)\n",
    "        e=time.time()\n",
    "        t2+=(e-s)\n",
    "        if write_video:\n",
    "            video_writer.write(frame)\n",
    "        count+=1\n",
    "    end=time.time()\n",
    "    total=end-start\n",
    "    fps=count/total\n",
    "    results=dict()\n",
    "    results['sr_freq']=sr_freq\n",
    "    results['resolution']=resolution\n",
    "    results['total_time']=total\n",
    "    results['fps']=fps\n",
    "    if write_video:\n",
    "        results['total_time_only_upscale']=t2\n",
    "        results['fps_only_upscale']=count/t2\n",
    "        metrics=subprocess.run(['ffmpeg-quality-metrics',output,ref_video,'--metrics','ssim', 'vmaf', 'psnr','-r','60','-t','12'],capture_output=True)\n",
    "        metrics_result=json.loads(metrics.stdout.decode('utf-8'))['global']\n",
    "        results['psnr']=metrics_result['psnr']['psnr_avg']['average']\n",
    "        results['ssim']=metrics_result['ssim']['ssim_avg']['average']\n",
    "        results['vmaf']=metrics_result['vmaf']['vmaf']['average']   \n",
    "        video_writer.release()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06241be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=pd.DataFrame(columns=['sr_freq','resolution','total_time','fps','total_time_only_upscale','fps_only_upscale','psnr','ssim','vmaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9836483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 1\n",
      "finish 1\n",
      "doing 2\n",
      "finish 2\n",
      "doing 3\n",
      "finish 3\n",
      "doing 4\n",
      "finish 4\n",
      "doing 5\n",
      "finish 5\n",
      "doing 6\n",
      "finish 6\n",
      "doing 7\n",
      "finish 7\n",
      "doing 8\n",
      "finish 8\n",
      "doing 9\n",
      "finish 9\n",
      "doing 10\n",
      "finish 10\n",
      "doing 11\n",
      "finish 11\n",
      "doing 12\n",
      "finish 12\n",
      "doing 13\n",
      "finish 13\n",
      "doing 14\n",
      "finish 14\n",
      "doing 15\n",
      "finish 15\n",
      "doing 16\n",
      "finish 16\n",
      "doing 17\n",
      "finish 17\n",
      "doing 18\n",
      "finish 18\n",
      "doing 19\n",
      "finish 19\n",
      "doing 20\n",
      "finish 20\n",
      "doing 21\n",
      "finish 21\n",
      "doing 22\n",
      "finish 22\n",
      "doing 23\n",
      "finish 23\n",
      "doing 24\n",
      "finish 24\n",
      "doing 25\n",
      "finish 25\n",
      "doing 26\n",
      "finish 26\n",
      "doing 27\n",
      "finish 27\n",
      "doing 28\n",
      "finish 28\n",
      "doing 29\n",
      "finish 29\n",
      "doing 30\n",
      "finish 30\n",
      "doing 31\n",
      "finish 31\n",
      "doing 32\n",
      "finish 32\n",
      "doing 33\n",
      "finish 33\n",
      "doing 34\n",
      "finish 34\n",
      "doing 35\n",
      "finish 35\n",
      "doing 36\n",
      "finish 36\n",
      "doing 37\n",
      "finish 37\n",
      "doing 38\n",
      "finish 38\n",
      "doing 39\n",
      "finish 39\n",
      "doing 40\n",
      "finish 40\n",
      "doing 41\n",
      "finish 41\n",
      "doing 42\n",
      "finish 42\n",
      "doing 43\n",
      "finish 43\n",
      "doing 44\n",
      "finish 44\n",
      "doing 45\n",
      "finish 45\n",
      "doing 46\n",
      "finish 46\n",
      "doing 47\n",
      "finish 47\n",
      "doing 48\n",
      "finish 48\n",
      "doing 49\n",
      "finish 49\n",
      "doing 50\n",
      "finish 50\n",
      "doing 51\n",
      "finish 51\n",
      "doing 52\n",
      "finish 52\n",
      "doing 53\n",
      "finish 53\n",
      "doing 54\n",
      "finish 54\n",
      "doing 55\n",
      "finish 55\n",
      "doing 56\n",
      "finish 56\n",
      "doing 57\n",
      "finish 57\n",
      "doing 58\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 204.00 MiB (GPU 3; 39.59 GiB total capacity; 690.96 MiB already allocated; 59.19 MiB free; 708.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68127/975186839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doing'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mout_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_video_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'r_{resolution[i]}_{sr_freq}_001.avi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_video\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_video\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_4k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdf_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdf_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result_sr3.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68127/2990910972.py\u001b[0m in \u001b[0;36mupscale\u001b[0;34m(video, sr_freq, resolution, model, write_video, output, ref_video)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msr_freq\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSR_upscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolution\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m'540p'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3840\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_68127/1495797985.py\u001b[0m in \u001b[0;36mSR_upscale\u001b[0;34m(model, in_img, num_frame)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimg_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoPIL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebook/oyzh/BasicSR-master/basicsr/archs/edvrOriginal_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mfeat_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mfeat_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_l1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;31m# L2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mfeat_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_l2_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_l1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebook/oyzh/BasicSR-master/basicsr/archs/arch_util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 204.00 MiB (GPU 3; 39.59 GiB total capacity; 690.96 MiB already allocated; 59.19 MiB free; 708.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "result_video_path='./SR_result_video'\n",
    "it=1\n",
    "for i,video in enumerate(video_list):\n",
    "    \n",
    "    model=model_list[i]\n",
    "    #model=EDVR_x4\n",
    "    for sr_freq in range(10,31):\n",
    "        print('doing',it)\n",
    "        out_video=os.path.join(result_video_path,f'r_{resolution[i]}_{sr_freq}_001.avi')\n",
    "        result=upscale(video,sr_freq,resolution[i],model,write_video=True,output=out_video,ref_video=video_4k)\n",
    "        df_result=df_result.append(result,ignore_index=True)\n",
    "        df_result.to_csv('result_sr3.csv',index=False)\n",
    "        print('finish',it)\n",
    "        it+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64890321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
